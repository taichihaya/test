{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2_BERT_livedoor_news_on_Google_Colaboratory_label_smoothing",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "deb981dac8894d1f86ffb629b6ad74e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00c6c93451724230b7a837f66acd1403",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd294097728843c7a3499c336eb6a05e",
              "IPY_MODEL_616fccfa5aae4835bd7a3a010fed44f5"
            ]
          }
        },
        "00c6c93451724230b7a837f66acd1403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd294097728843c7a3499c336eb6a05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bffe23760330488d9cc46bea0e852215",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 257706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 257706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0e42b09dd454259a0359fcf288b5fb9"
          }
        },
        "616fccfa5aae4835bd7a3a010fed44f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b14558a8707f4acf8611fc1a9088bd92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 258k/258k [00:00&lt;00:00, 3.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56bfaa4d779b4aa49c772ad622a2f08f"
          }
        },
        "bffe23760330488d9cc46bea0e852215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0e42b09dd454259a0359fcf288b5fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b14558a8707f4acf8611fc1a9088bd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56bfaa4d779b4aa49c772ad622a2f08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eee76480d86b49df975d3f605d83deca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_063786e38a874b679d95838eb532aad1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cbaccabccab46ec8192c16c370846dd",
              "IPY_MODEL_647b91bd9d69487f8b3f1c14c56ca5d8"
            ]
          }
        },
        "063786e38a874b679d95838eb532aad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cbaccabccab46ec8192c16c370846dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fb1ca155fa24978b6711c626a9aa41c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_138cb33920d943768fe6902a8d2066f9"
          }
        },
        "647b91bd9d69487f8b3f1c14c56ca5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_468fba5bf45f46a8bb48169b604e85cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:49&lt;00:00, 3.97B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df0631ef039f4850b591ec3f1ba8e8ac"
          }
        },
        "1fb1ca155fa24978b6711c626a9aa41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "138cb33920d943768fe6902a8d2066f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "468fba5bf45f46a8bb48169b604e85cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df0631ef039f4850b591ec3f1ba8e8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dbbb26a0cc549889461de80b86cbfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57e9c309d7ae49bd9d3b57226261e00a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c67946c690ce4954aecadba26bfc09d7",
              "IPY_MODEL_b3308a67722e4fc5ac68f8ee16bc208f"
            ]
          }
        },
        "57e9c309d7ae49bd9d3b57226261e00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c67946c690ce4954aecadba26bfc09d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4e5c265c11e4874924daaa159f4b66f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445021143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445021143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fe5217f23b14b5da5fea2f70ce49555"
          }
        },
        "b3308a67722e4fc5ac68f8ee16bc208f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3ec2986e02b494e95679c725301b2cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:06&lt;00:00, 69.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97c8ede560a8408d8c0137c969768da7"
          }
        },
        "d4e5c265c11e4874924daaa159f4b66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fe5217f23b14b5da5fea2f70ce49555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3ec2986e02b494e95679c725301b2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97c8ede560a8408d8c0137c969768da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taichihaya/test/blob/master/2_BERT_livedoor_news_on_Google_Colaboratory_label_smoothing_r1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYlVm0kpjx57"
      },
      "source": [
        "## 日本語BERTでlivedoorニュースを教師あり学習で分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqIW6ar2Bm3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f6fd75-155b-4fa5-a1ca-c541f0af393b"
      },
      "source": [
        "# 乱数シードの固定\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED_VALUE = 1234  # これはなんでも良い\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)  # PyTorchを使う場合\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f488d67e570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii-mqaAhCApI"
      },
      "source": [
        "### GPUの使用可能を確認\n",
        "\n",
        "画面上部のメニュー ランタイム > ランタイムのタイプを変更 で、 ノートブックの設定 を開く\n",
        "\n",
        "ハードウェアアクセラレータに GPU を選択し、 保存 する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8TJgawCB_Nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a3f28d-1302-460e-ee72-4c123fbe93b9"
      },
      "source": [
        "# GPUの使用確認：True or False\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# TrueならGPU使用可能"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6dbVUfj1W-"
      },
      "source": [
        "## 準備1：Livedoorニュースをダウンロードしてtsvファイル化\n",
        "\n",
        "参考：https://github.com/yoheikikuta/bert-japanese/blob/master/notebook/finetune-to-livedoor-corpus.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vh0a49Gp-rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d24654-d22d-4cf1-ee97-8d7bed3c8688"
      },
      "source": [
        "# Livedoorニュースのファイルをダウンロード\n",
        "! wget \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-19 23:35:25--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  3.01MB/s    in 2.8s    \n",
            "\n",
            "2020-11-19 23:35:29 (3.01 MB/s) - ‘ldcc-20140209.tar.gz’ saved [8855190/8855190]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keY2WGdwjzLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80afbb5f-1a67-4ee6-89e5-f30763972dd0"
      },
      "source": [
        "# ファイルを解凍し、カテゴリー数と内容を確認\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "# 解凍\n",
        "tar = tarfile.open(\"ldcc-20140209.tar.gz\", \"r:gz\")\n",
        "tar.extractall(\"./data/livedoor/\")\n",
        "tar.close()\n",
        "\n",
        "# フォルダのファイルとディレクトリを確認\n",
        "files_folders = [name for name in os.listdir(\"./data/livedoor/text/\")]\n",
        "print(files_folders)\n",
        "\n",
        "# カテゴリーのフォルダのみを抽出\n",
        "categories = [name for name in os.listdir(\n",
        "    \"./data/livedoor/text/\") if os.path.isdir(\"./data/livedoor/text/\"+name)]\n",
        "\n",
        "print(\"カテゴリー数:\", len(categories))\n",
        "print(categories)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it-life-hack', 'dokujo-tsushin', 'smax', 'sports-watch', 'README.txt', 'topic-news', 'movie-enter', 'peachy', 'CHANGES.txt', 'kaden-channel', 'livedoor-homme']\n",
            "カテゴリー数: 9\n",
            "['it-life-hack', 'dokujo-tsushin', 'smax', 'sports-watch', 'topic-news', 'movie-enter', 'peachy', 'kaden-channel', 'livedoor-homme']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z201OQ7gvYOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecccc42b-5e9f-432f-ebce-be7b44d34b71"
      },
      "source": [
        "# ファイルの中身を確認してみる\n",
        "file_name = \"./data/livedoor/text/movie-enter/movie-enter-6255260.txt\"\n",
        "\n",
        "with open(file_name) as text_file:\n",
        "    text = text_file.readlines()\n",
        "    print(\"0：\", text[0])  # URL情報\n",
        "    print(\"1：\", text[1])  # タイムスタンプ\n",
        "    print(\"2：\", text[2])  # タイトル\n",
        "    print(\"3：\", text[3])  # 本文\n",
        "\n",
        "    # 今回は4要素目には本文は伸びていないが、4要素目以降に本文がある場合もある\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0： http://news.livedoor.com/article/detail/6255260/\n",
            "\n",
            "1： 2012-02-07T09:00:00+0900\n",
            "\n",
            "2： 新しいヴァンパイアが誕生！　ジョニデ主演『ダーク・シャドウ』の公開日が決定\n",
            "\n",
            "3： 　こんなヴァンパイアは見たことがない！　ジョニー・デップとティム・バートン監督がタッグを組んだ映画『ダーク・シャドウズ（原題）』の邦題が『ダーク・シャドウ』に決定。日本公開日が5月19日に決まった。さらに、ジョニー・デップ演じるヴァンパイアの写真が公開された。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoKvaAK1vurV"
      },
      "source": [
        "# 本文を取得する前処理関数を定義\n",
        "\n",
        "\n",
        "def extract_main_txt(file_name):\n",
        "    with open(file_name) as text_file:\n",
        "        # 今回はタイトル行は外したいので、3要素目以降の本文のみ使用\n",
        "        text = text_file.readlines()[3:]\n",
        "\n",
        "        # 3要素目以降にも本文が入っている場合があるので、リストにして、後で結合させる\n",
        "        text = [sentence.strip() for sentence in text]  # 空白文字(スペースやタブ、改行)の削除\n",
        "        text = list(filter(lambda line: line != '', text))\n",
        "        text = ''.join(text)\n",
        "        text = text.translate(str.maketrans(\n",
        "            {'\\n': '', '\\t': '', '\\r': '', '\\u3000': ''}))  # 改行やタブ、全角スペースを消す\n",
        "        return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq2ebKoOxThi"
      },
      "source": [
        "# リストに前処理した本文と、カテゴリーのラベルを追加していく\n",
        "import glob\n",
        "\n",
        "list_text = []\n",
        "list_label = []\n",
        "\n",
        "for cat in categories:\n",
        "    text_files = glob.glob(os.path.join(\"./data/livedoor/text\", cat, \"*.txt\"))\n",
        "\n",
        "    # 前処理extract_main_txtを実施して本文を取得\n",
        "    body = [extract_main_txt(text_file) for text_file in text_files]\n",
        "\n",
        "    label = [cat] * len(body)  # bodyの数文だけカテゴリー名のラベルのリストを作成\n",
        "\n",
        "    list_text.extend(body)  # appendが要素を追加するのに対して、extendはリストごと追加する\n",
        "    list_label.extend(label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKPb_LJxxuOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c989b8-cf9a-49c1-e67d-c1fbe9b1a1b2"
      },
      "source": [
        "# 0番目の文章とラベルを確認\n",
        "print(list_text[0])\n",
        "print(list_label[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "従来、OSとOfficeソフトを中心に展開していたマイクロソフトが、方針転換を始めたようだ。Surfaceでハードウェアも提供するようになり、OSやUIも各デバイスで共通化するなど次世代に向けて動き始めた。■基本的にどのデバイスでも同じOS、同じユーザー体験へWindows Phone 8は従来のWindows Phoneとは変わり、OSの主要部分がPCのWindows 8と共通になるようだ。Surfaceのようなタブレット端末はCPU別に2つのOSが用意される。スマートフォンのようなARM向けのCPUを搭載したWindows RTと、従来のパソコンと同等のx86を搭載した通常のWindows 8だ。それぞれのOSは主要な部分が共通化し、タブレットのWindows RTとWindows Phone 8はCPUが同じなので、OS自体もかなり近い物になりそうだ。x86のCPUを採用するタブレットはキーボードがないだけで、OSはもちろんハードウェアも通常のパソコンと同じだ。それぞれのデバイスではMetro UIを使用し、ユーザー体験はそれぞれのデバイスで同じような物となる。これらはコンシューマー向けの製品だが、サーバー向けの次期OS Windows Server 2012でもMetroは使われるようで、マイクロソフト製品を使う限り、携帯電話からサーバーまで同等の使い勝手となる。■次世代に向けてパソコン以上に現在急成長しているのはスマートフォンと、タブレットだ。タブレット自体はマイクロソフトが2002年に提供したWindows XP Tablet Editionから本格的に対応している。当時はデバイス自体も未熟で、その後もいくつかの製品が登場したが、Windowsのタブレットはヒットしないままだった。そんな中で、アップルのiPadは2010年に登場するとたちまち大成功と言えるほど、世界中で人気商品となってしまった。iPadの成功はiPad専用アプリの存在など、様々な要因がありそうだが、利用しているユーザーの総合的な満足度が高い事が上げられる。ハードウェアやOS、アプリなどの総合的な満足度を上げるには、それらをすべて自社で提供できた方が有利だ。Androidタブレットもいくつかのハードウェアは提供されているものの、iPadほど売れているとはいえない。マイクロソフトはSurfaceのハードウェアを自社で提供することで、タブレットの普及に向けて本格的に力を入れる。パソコンやスマートフォンでも、OSの基本的な部分を各デバイスでできる限り共通化し、ユーザーにはMetro UIでユーザー体験を共通化する。これらの動きがどうなるかは、実際の製品がどれだけ魅力的なものになるかにかかっており、今後の製品展開に注目したい。上倉賢 @kamikura [digi2(デジ通)]digi2は「デジタル通」の略です。現在のデジタル機器は使いこなしが難しくなっています。皆さんがデジタル機器の「通」に近づくための情報を、皆さんよりすこし通な執筆陣が提供します。■デジ通の記事をもっと見る・iPhone 4Sの音声認識機能は使える 新しいiPadでも使える音声認識・英語の音声認識で英会話練習 自分の発音を客観的に知る方法・サービス終了後はどうなる！電子書籍は永遠に読めるのか・キンドルが日本に参入する？Amazonの電子書籍をおさらい・iPhoneが据え置きゲーム機も殺す？多機能化するスマートフォン【キヤノン純正インク】キャノンインクタンク 5色マルチパック BCI-321+320/5MPキヤノン販売元：Amazon.co.jpクチコミを見る\n",
            "it-life-hack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Kf1D9xxuvP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "861eb448-cb1f-4a5b-9030-359192be2abc"
      },
      "source": [
        "# pandasのDataFrameにする\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'text': list_text, 'label': list_label})\n",
        "\n",
        "# 大きさを確認しておく（7,376文章が存在）\n",
        "print(df.shape)\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7376, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>従来、OSとOfficeソフトを中心に展開していたマイクロソフトが、方針転換を始めたようだ。...</td>\n",
              "      <td>it-life-hack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012年は多くに天体イベントがある天体イヤーだ。星や天体への関心高くなり、空を見上げる人も...</td>\n",
              "      <td>it-life-hack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>最近では仕事での付き合いから、Facebookアカウントを交換することが増えてきた。周囲がや...</td>\n",
              "      <td>it-life-hack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>英会話を学んでから何年も経ってしまうと覚えていたハズのフレーズすら出てこなくなりますよね。か...</td>\n",
              "      <td>it-life-hack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>タイトルの写真、何かわかるだろうか？ルイ・ヴィトンでしょ？まあその通りなのだが、これケーキだ...</td>\n",
              "      <td>it-life-hack</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text         label\n",
              "0  従来、OSとOfficeソフトを中心に展開していたマイクロソフトが、方針転換を始めたようだ。...  it-life-hack\n",
              "1  2012年は多くに天体イベントがある天体イヤーだ。星や天体への関心高くなり、空を見上げる人も...  it-life-hack\n",
              "2  最近では仕事での付き合いから、Facebookアカウントを交換することが増えてきた。周囲がや...  it-life-hack\n",
              "3  英会話を学んでから何年も経ってしまうと覚えていたハズのフレーズすら出てこなくなりますよね。か...  it-life-hack\n",
              "4  タイトルの写真、何かわかるだろうか？ルイ・ヴィトンでしょ？まあその通りなのだが、これケーキだ...  it-life-hack"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8p83xi02ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "a5073184-a08f-4b2a-f187-8ff7f8dd71b5"
      },
      "source": [
        "# カテゴリーの辞書を作成\n",
        "dic_id2cat = dict(zip(list(range(len(categories))), categories))\n",
        "dic_cat2id = dict(zip(categories, list(range(len(categories)))))\n",
        "\n",
        "print(dic_id2cat)\n",
        "print(dic_cat2id)\n",
        "\n",
        "# DataFrameにカテゴリーindexの列を作成\n",
        "df[\"label_index\"] = df[\"label\"].map(dic_cat2id)\n",
        "df.head()\n",
        "\n",
        "# label列を消去し、text, indexの順番にする\n",
        "df = df.loc[:, [\"text\", \"label_index\"]]\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'it-life-hack', 1: 'dokujo-tsushin', 2: 'smax', 3: 'sports-watch', 4: 'topic-news', 5: 'movie-enter', 6: 'peachy', 7: 'kaden-channel', 8: 'livedoor-homme'}\n",
            "{'it-life-hack': 0, 'dokujo-tsushin': 1, 'smax': 2, 'sports-watch': 3, 'topic-news': 4, 'movie-enter': 5, 'peachy': 6, 'kaden-channel': 7, 'livedoor-homme': 8}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>従来、OSとOfficeソフトを中心に展開していたマイクロソフトが、方針転換を始めたようだ。...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012年は多くに天体イベントがある天体イヤーだ。星や天体への関心高くなり、空を見上げる人も...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>最近では仕事での付き合いから、Facebookアカウントを交換することが増えてきた。周囲がや...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>英会話を学んでから何年も経ってしまうと覚えていたハズのフレーズすら出てこなくなりますよね。か...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>タイトルの写真、何かわかるだろうか？ルイ・ヴィトンでしょ？まあその通りなのだが、これケーキだ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label_index\n",
              "0  従来、OSとOfficeソフトを中心に展開していたマイクロソフトが、方針転換を始めたようだ。...            0\n",
              "1  2012年は多くに天体イベントがある天体イヤーだ。星や天体への関心高くなり、空を見上げる人も...            0\n",
              "2  最近では仕事での付き合いから、Facebookアカウントを交換することが増えてきた。周囲がや...            0\n",
              "3  英会話を学んでから何年も経ってしまうと覚えていたハズのフレーズすら出てこなくなりますよね。か...            0\n",
              "4  タイトルの写真、何かわかるだろうか？ルイ・ヴィトンでしょ？まあその通りなのだが、これケーキだ...            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaE_8vER18xY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "088e5f03-41a2-4aa6-d2a0-173e6af65329"
      },
      "source": [
        "# 順番をシャッフルする\n",
        "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>——この番組の見所は何だと思いますか？マット・ボマー：この番組の魅力は、究極的には、すごく型...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Android版ダウンロード：iPhone版「ガール」のためのニュースは「Peachy（才職...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21日発売の「週刊ポスト」は、今日にもメジャー移籍に向けたFA宣言を行うと目されていた東北楽...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>マリリン・モンロー没後50年、初めて明かされる恋——。世界のセックス・シンボルと謳われたマリ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7日、前大阪府知事・橋下徹氏のコメントが、ネット掲示板を中心に大きな話題になっている。共産党...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label_index\n",
              "0  ——この番組の見所は何だと思いますか？マット・ボマー：この番組の魅力は、究極的には、すごく型...            5\n",
              "1  Android版ダウンロード：iPhone版「ガール」のためのニュースは「Peachy（才職...            6\n",
              "2  21日発売の「週刊ポスト」は、今日にもメジャー移籍に向けたFA宣言を行うと目されていた東北楽...            3\n",
              "3  マリリン・モンロー没後50年、初めて明かされる恋——。世界のセックス・シンボルと謳われたマリ...            5\n",
              "4  7日、前大阪府知事・橋下徹氏のコメントが、ネット掲示板を中心に大きな話題になっている。共産党...            4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRrt-XH72C3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3524e190-257c-4708-825d-b5723e7c3545"
      },
      "source": [
        "# tsvファイルで保存する\n",
        "\n",
        "# 全体の2割の文章数\n",
        "len_0_2 = len(df) // 5\n",
        "\n",
        "# 前から2割をテストデータとする\n",
        "df[:len_0_2].to_csv(\"./test.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[:len_0_2].shape)\n",
        "\n",
        "# 前2割からを訓練&検証データとする\n",
        "df[len_0_2:].to_csv(\"./train_eval.tsv\", sep='\\t', index=False, header=None)\n",
        "print(df[len_0_2:].shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1475, 2)\n",
            "(5901, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0NykW7u3Mw9"
      },
      "source": [
        "# tsvファイルをダウンロードしたい場合\n",
        "from google.colab import files\n",
        "\n",
        "# ダウンロードする場合はコメントを外す\n",
        "# 少し時間がかかる（4MB）\n",
        "# files.download(\"./test.tsv\")\n",
        "\n",
        "\n",
        "# ダウンロードする場合はコメントを外す\n",
        "# 少し時間がかかる（18MB）\n",
        "# files.download(\"./train_eval.tsv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPT3Pjr94oPW"
      },
      "source": [
        "## 準備2：LivedoorニュースをBERT用のDataLoaderにする\n",
        "\n",
        "Hugginfaceのリポジトリの案内とは異なり、torchtextを使用した手法で実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXX4pr2-kY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48cd0eb-e71d-4104-88f9-a3c095ff9a10"
      },
      "source": [
        "# MeCabとtransformersの用意\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "!pip install transformers==2.9.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30 swig swig3.0\n",
            "0 upgraded, 23 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 4,978 kB of archives.\n",
            "After this operation, 21.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 4,978 kB in 1s (4,522 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Selecting previously unselected package swig3.0.\n",
            "Preparing to unpack .../21-swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../22-swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.10)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.10)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "0 packages upgraded, 11 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 2s (19.1 MB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 146043 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "                            \n",
            "Collecting mecab-python3==0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python3: filename=mecab_python3-0.7-cp36-cp36m-linux_x86_64.whl size=155480 sha256=81baa62ef2b1f935350be0fd961a9ae3938596dcd6bd807482f3a45605338613\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n",
            "Collecting transformers==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/38/c9527aa055241c66c4d785381eaf6f80a28c224cae97daa1f8b183b5fabb/transformers-2.9.0-py3-none-any.whl (635kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 12.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 57.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4ba97b9e7a97d8c8c07e376aadd784945b6cdafe1dfcde007d54107821727d0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tKqo2TF9vzj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "deb981dac8894d1f86ffb629b6ad74e6",
            "00c6c93451724230b7a837f66acd1403",
            "fd294097728843c7a3499c336eb6a05e",
            "616fccfa5aae4835bd7a3a010fed44f5",
            "bffe23760330488d9cc46bea0e852215",
            "e0e42b09dd454259a0359fcf288b5fb9",
            "b14558a8707f4acf8611fc1a9088bd92",
            "56bfaa4d779b4aa49c772ad622a2f08f"
          ]
        },
        "outputId": "b19c5414-accb-4940-d092-c0dd54cc8300"
      },
      "source": [
        "import torch\n",
        "import torchtext  # torchtextを使用\n",
        "from transformers.modeling_bert import BertModel\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "\n",
        "# 日本語BERTの分かち書き用tokenizerです\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(\n",
        "    'bert-base-japanese-whole-word-masking')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "deb981dac8894d1f86ffb629b6ad74e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZypBWaE-PB6"
      },
      "source": [
        "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "\n",
        "max_length = 512  # 東北大学_日本語版の最大の単語数（サブワード数）は512\n",
        "\n",
        "\n",
        "def tokenizer_512(input_text):\n",
        "    \"\"\"torchtextのtokenizerとして扱えるように、512単語のpytorchでのencodeを定義。ここで[0]を指定し忘れないように\"\"\"\n",
        "    return tokenizer.encode(input_text, max_length=512, return_tensors='pt')[0]\n",
        "\n",
        "\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_512, use_vocab=False, lower=False,\n",
        "                            include_lengths=True, batch_first=True, fix_length=max_length, pad_token=0)\n",
        "# 注意：tokenize=tokenizer.encodeと、.encodeをつけます。padding[PAD]のindexが0なので、0を指定します。\n",
        "\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# (注釈)：各引数を再確認\n",
        "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
        "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
        "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
        "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
        "# include_length: 文章の単語数のデータを保持するか\n",
        "# batch_first：ミニバッチの次元を用意するかどうか\n",
        "# fix_length：全部の文章をfix_lengthと同じ長さになるように、paddingします\n",
        "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyLNL-sd_Xd5"
      },
      "source": [
        "# 各tsvファイルを読み込み、分かち書きをしてdatasetにします\n",
        "# 少し時間がかかります\n",
        "# train_eval：5901個、test：1475個\n",
        "dataset_train_eval, dataset_test = torchtext.data.TabularDataset.splits(\n",
        "    path='.', train='train_eval.tsv', test='test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNRofv_iDOYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9449061-5267-457a-81b1-8a181cdc13e5"
      },
      "source": [
        "# torchtext.data.Datasetのsplit関数で訓練データと検証データを分ける\n",
        "# train_eval：5901個、test：1475個\n",
        "\n",
        "dataset_train, dataset_eval = dataset_train_eval.split(\n",
        "    split_ratio=1.0 - 1475/5901, random_state=random.seed(1234))\n",
        "\n",
        "# datasetの長さを確認してみる\n",
        "print(dataset_train.__len__())\n",
        "print(dataset_eval.__len__())\n",
        "print(dataset_test.__len__())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4426\n",
            "1475\n",
            "1475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_XilciAI2la",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72fb82a7-4e98-4983-9e56-6a937e026cb7"
      },
      "source": [
        "# datasetの中身を確認してみる\n",
        "item = next(iter(dataset_train))\n",
        "print(item.Text)\n",
        "print(\"長さ：\", len(item.Text))  # 長さを確認 [CLS]から始まり[SEP]で終わる。512より長いと後ろが切れる\n",
        "print(\"ラベル：\", item.Label)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    2,  6369,     9,     6,  2399,   530,     5,  7911, 28493, 28472,\n",
            "         1358, 28523,  4172,    23, 20648,    24,    35,  6406,  3151,    11,\n",
            "         1389,    15,    10,  5114,  9949,    11,   602,    15,    10,     8,\n",
            "         7911, 28493, 28472,  1358,  1652,  4172, 22671, 20713,     9,     6,\n",
            "          744,   126,     5,   120,    13,  2504,  3238,    35,  7223,     6,\n",
            "          107, 18548,     6,   107, 17083,     6,   107,  7904, 28833,   245,\n",
            "          140,  5842,    14,    31,    13,   625,     8,  7168,     6,  6369,\n",
            "           14,   602,    15,    10,     5,     9,   213,  4859,     8,   107,\n",
            "        21990,     7,   705,    14, 12932,    36,  5685,  1581,  2881,    38,\n",
            "           57,  4859,     6,  6724,  5464,     7,  1277,    15,    10,    36,\n",
            "         3593,    35, 23171,  2586,  2881,    38,    57,  4859,     6,   324,\n",
            "          176,    13,   139,     6,  8938, 13856,   129,    64,    11, 11150,\n",
            "        15988,   186,     7, 13258,    15,    10,    36, 16714,  9904, 28634,\n",
            "         1128,  8778,    38,    17,  4859,     6, 21115, 18688, 10216,  1389,\n",
            "            5,    36, 21522,   834,  2881,    38,    17,  4859,     6,   326,\n",
            "        29999, 28457,   519,    18,    36,  1784,  2881,    38,    17,  4859,\n",
            "           13,  7112,    18, 11771,    14, 28285,    16,    33,     8,  6890,\n",
            "        14606,     7,  1943,    16,  7454,    45,    14,   392,     8,  6724,\n",
            "         5464,    49, 21024,  6032,     5,  3200,   225,     6,  1400,    18,\n",
            "        10948,     7,  1943,    10,  2881,    11,  2820,    15,    16,    33,\n",
            "          140,    45,  3635,   205,     8,   213,    37,   121,    32,   603,\n",
            "         8184,   580,    26,    62,     8,  7911, 28493, 28472,  1358, 28523,\n",
            "         4172, 28472, 22671,  1389,  5114,  9949,    23,  6369,    24, 31407,\n",
            "         1634,  2622,    35, 18060,   241, 25997,    35,   771, 30810,  3876,\n",
            "           12, 16812, 28136,  9680,  9317, 29760,  9398,  9594,    35,  9680,\n",
            "         4459,  9594,  2371,  4973,     5,   324,  4233,     7,  4413,  2621,\n",
            "           28,  1277,     7,    35, 15118,     5,    36,  1144, 13025,    38,\n",
            "            7,   147,  1317,   656,   679, 28496, 18870,    61, 28369,  6420,\n",
            "          439,    38,     9,  7643, 12183,  1676,    14,  8583,    35,  9680,\n",
            "         4459,  9594, 15534,    13,  7469,  9802,   679,  5521,   122,    14,\n",
            "           36, 14739, 22228, 28479, 28649,  1269,    38,    11,   127,   228,\n",
            "        26017,   125,     7, 10439,   679,    35,   969,  1571,     5,  1218,\n",
            "         9999,   834, 16172,     9, 16050,  2819,    36, 25924, 28697,   500,\n",
            "           61,   318,    48,    38,     3])\n",
            "長さ： 335\n",
            "ラベル： 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7323f5aJFzz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "09e162d4-a922-4624-a319-0e00ad18352f"
      },
      "source": [
        "# datasetの中身を文章に戻し、確認\n",
        "\n",
        "print(tokenizer.convert_ids_to_tokens(item.Text.tolist()))  # 文章\n",
        "dic_id2cat[int(item.Label)]  # id\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'ソニー', 'は', '、', '独自', '開発', 'の', 'バランス', '##ド', '##・', '##アー', '##マ', '##チュア', '(', 'BA', ')', '・', 'ドライバー', 'ユニット', 'を', '搭載', 'し', 'た', 'ヘッド', '##ホン', 'を', '発表', 'し', 'た', '。', 'バランス', '##ド', '##・', '##アー', '##マー', '##チュア', '##ドライバー', '##ユニット', 'は', '、', '今', 'まで', 'の', 'もの', 'と', '比べ', '小型', '・', '軽量', '、', '高', '感度', '、', '高', '解像度', '、', '高', '遮', '##音', '性', 'という', '特性', 'が', 'ある', 'と', 'いう', '。', '今回', '、', 'ソニー', 'が', '発表', 'し', 'た', 'の', 'は', '11', '機種', '。', '高', '音質', 'に', '音楽', 'が', '楽しめる', '「', 'リス', '##ニング', 'タイプ', '」', '4', '機種', '、', 'スマート', 'フォン', 'に', '対応', 'し', 'た', '「', 'マイク', '・', 'リモコン', '付き', 'タイプ', '」', '4', '機種', '、', '世界', '初', 'と', 'なる', '、', '電池', '収納', '部', 'など', 'を', 'ハウ', '##ジング', '内', 'に', '集約', 'し', 'た', '「', 'ノイズ', '##キャン', '##セ', '##リング', '##タイプ', '」', '1', '機種', '、', 'Blue', '##to', '##oth', '搭載', 'の', '「', 'ワイヤ', '##レス', 'タイプ', '」', '1', '機種', '、', '水', '##洗', '##い', '可能', 'な', '「', 'スポーツ', 'タイプ', '」', '1', '機種', 'と', '豊富', 'な', 'ラインナップ', 'が', 'そろっ', 'て', 'いる', '。', 'ライフ', '##スタイル', 'に', '合わせ', 'て', '選ぶ', 'こと', 'が', 'できる', '。', 'スマート', 'フォン', 'や', 'タブレット', '端末', 'の', '普及', 'により', '、', '様々', 'な', 'ニーズ', 'に', '合わせ', 'た', 'タイプ', 'を', '提案', 'し', 'て', 'いる', 'という', 'こと', 'だろ', 'う', '。', '11', '月', '10', '日', '以降', '順次', '発売', 'さ', 'れる', '。', 'バランス', '##ド', '##・', '##アー', '##マ', '##チュア', '##・', '##ドライバー', '搭載', 'ヘッド', '##ホン', '(', 'ソニー', ')', '##■', '関連', '記事', '・', 'iPhone', '用', '防水', '・', '防', '##塵', 'ケース', 'で', '快適', 'サイクリング', '【', '売れ', '##筋', 'チェック', '】', '・', '【', '話題', '】', '電子', '書籍', 'の', '世界', '規格', 'に', '縦', '書き', 'も', '対応', 'に', '・', 'パナソニック', 'の', '「', '旅', 'ナビ', '」', 'に', '新', 'モデル', '登場', '!', '##「', 'CN', '-', 'MH', '01', 'L', '」', 'は', 'ガイド', '##ブック', 'データ', 'が', '充実', '・', '【', '話題', '】', '押す', 'と', 'しゃ', '##べる', '!', 'テレ', '東', 'が', '「', 'ピカ', '##チュウ', '##リ', '##モ', '##コン', '」', 'を', '7', ',', '777', '名', 'に', 'プレゼント', '!', '・', '女性', '人気', 'の', '高い', 'ミラー', '##レス', '##カメラ', 'は', 'オリン', '##パス', '「', 'PE', '##N', 'E', '-', 'P', '3', '」', '[SEP]']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kaden-channel'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qiBmmdsJ-aK"
      },
      "source": [
        "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "batch_size = 16  # BERTでは16、32あたりを使用する\n",
        "\n",
        "dl_train = torchtext.data.Iterator(\n",
        "    dataset_train, batch_size=batch_size, train=True)\n",
        "\n",
        "dl_eval = torchtext.data.Iterator(\n",
        "    dataset_eval, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "dl_test = torchtext.data.Iterator(\n",
        "    dataset_test, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": dl_train, \"val\": dl_eval}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sNpiK5K14s"
      },
      "source": [
        "# DataLoaderの動作確認 \n",
        "\n",
        "batch = next(iter(dl_test))\n",
        "print(batch)\n",
        "print(batch.Text[0].shape)\n",
        "print(batch.Label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8e6NhQ3cLcq"
      },
      "source": [
        "## 準備3：BERTのクラス分類用のモデルを用意する\n",
        "\n",
        "Huggingfaceさんのをそのまま使うのではなく、BERTのbaseだけ使い、残りは自分で実装する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFlvnI05a4xN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eee76480d86b49df975d3f605d83deca",
            "063786e38a874b679d95838eb532aad1",
            "1cbaccabccab46ec8192c16c370846dd",
            "647b91bd9d69487f8b3f1c14c56ca5d8",
            "1fb1ca155fa24978b6711c626a9aa41c",
            "138cb33920d943768fe6902a8d2066f9",
            "468fba5bf45f46a8bb48169b604e85cc",
            "df0631ef039f4850b591ec3f1ba8e8ac",
            "7dbbb26a0cc549889461de80b86cbfd6",
            "57e9c309d7ae49bd9d3b57226261e00a",
            "c67946c690ce4954aecadba26bfc09d7",
            "b3308a67722e4fc5ac68f8ee16bc208f",
            "d4e5c265c11e4874924daaa159f4b66f",
            "7fe5217f23b14b5da5fea2f70ce49555",
            "e3ec2986e02b494e95679c725301b2cb",
            "97c8ede560a8408d8c0137c969768da7"
          ]
        },
        "outputId": "3e9c0e80-b77d-4214-dcb3-92466ed5262d"
      },
      "source": [
        "from transformers.modeling_bert import BertModel\n",
        "\n",
        "# BERTの日本語学習済みパラメータのモデルです\n",
        "model = BertModel.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eee76480d86b49df975d3f605d83deca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dbbb26a0cc549889461de80b86cbfd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445021143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BgGd7fLPssV"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class BertForLivedoor(nn.Module):\n",
        "    '''BERTモデルにLivedoorニュースの9クラスを判定する部分をつなげたモデル'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BertForLivedoor, self).__init__()\n",
        "\n",
        "        # BERTモジュール\n",
        "        self.bert = model  # 日本語学習済みのBERTモデル\n",
        "\n",
        "        # self.drop = nn.Dropout(p=0.3)\n",
        "\n",
        "        # headにポジネガ予測を追加\n",
        "        # 入力はBERTの出力特徴量の次元768、出力は9クラス\n",
        "        self.cls = nn.Linear(in_features=768, out_features=9)\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.cls.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls.bias, 0)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        '''\n",
        "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
        "        '''\n",
        "\n",
        "        # BERTの基本モデル部分の順伝搬\n",
        "        # 順伝搬させる\n",
        "        result = self.bert(input_ids)  # reult は、sequence_output, pooled_output\n",
        "\n",
        "        # sequence_outputの先頭の単語ベクトルを抜き出す\n",
        "        vec_0 = result[0]  # 最初の0がsequence_outputを示す\n",
        "        vec_0 = vec_0[:, 0, :]  # 全バッチ。先頭0番目の単語の全768要素\n",
        "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_size]に変換\n",
        "\n",
        "        # vec_0 = self.drop(vec_0) # dropout\n",
        "\n",
        "        output = self.cls(vec_0)  # 全結合層\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOtveynWRwK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95056689-0067-40b9-8ed1-f6c11b2e5fd9"
      },
      "source": [
        "# モデル構築\n",
        "net = BertForLivedoor()\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ネットワーク設定完了\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkg7r2RIR7qU"
      },
      "source": [
        "## 準備4：BERTのファインチューニングの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPGYvX4RR3UT"
      },
      "source": [
        "# 勾配計算を最後のBertLayerモジュールと追加した分類アダプターのみ実行\n",
        "\n",
        "# 1. まず全部を、勾配計算Falseにしてしまう\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. BertLayerモジュールの最後を勾配計算ありに変更\n",
        "for param in net.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. 識別器を勾配計算ありに変更\n",
        "for param in net.cls.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPD0zlJF3v6f"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "def linear_combination(x, y, epsilon): \n",
        "    return epsilon*x + (1-epsilon)*y\n",
        "\n",
        "def reduce_loss(loss, reduction='mean'):\n",
        "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, epsilon:float=0.2, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.reduction = reduction\n",
        "    \n",
        "    def forward(self, preds, target):\n",
        "        n = preds.size()[-1]\n",
        "        log_preds = F.log_softmax(preds, dim=-1)\n",
        "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
        "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
        "        return linear_combination(loss/n, nll, self.epsilon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWYbBdkF5Uvp"
      },
      "source": [
        "class LabelSmoothingCrossEntropy2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LabelSmoothingCrossEntropy2, self).__init__()\n",
        "    def forward(self, x, target, smoothing=0.1):\n",
        "        confidence = 1. - smoothing\n",
        "        logprobs = F.log_softmax(x, dim=-1)\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = confidence * nll_loss + smoothing * smooth_loss\n",
        "        return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il_-wow4Suwe"
      },
      "source": [
        "# 最適化手法の設定\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "    {'params': net.cls.parameters(), 'lr': 1e-4}\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 損失関数の設定\n",
        "# criterion = LabelSmoothingCrossEntropy() # 1回目 正解率：0.9261\n",
        "# criterion = LabelSmoothingCrossEntropy() # 1回目 正解率：smothing0.2 0.9261\n",
        "criterion = LabelSmoothingCrossEntropy2() # 2回目 正解率：\n",
        "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu7KRn1bTIQp"
      },
      "source": [
        "## 5. 訓練を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNaAXgiITFiw"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "            iteration = 1\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            print('イテレーション {} || Loss: {:.4f} || 10iter. || 本イテレーションの正解率：{}'.format(\n",
        "                                iteration, loss.item(),  acc))\n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfnH-gAmS75e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39a4f9a-c0a5-41ab-d2a9-d30ee124ce5a"
      },
      "source": [
        "# 学習・検証を実行する。1epochに2分ほどかかります\n",
        "num_epochs = 4\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "イテレーション 10 || Loss: 0.6003 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 20 || Loss: 0.6290 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 30 || Loss: 0.5485 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 40 || Loss: 0.5535 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 50 || Loss: 0.5490 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 60 || Loss: 0.6041 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 70 || Loss: 0.6530 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 80 || Loss: 0.5406 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 90 || Loss: 0.5219 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 100 || Loss: 0.5476 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 110 || Loss: 0.5465 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 120 || Loss: 0.5420 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 130 || Loss: 0.5515 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 140 || Loss: 0.5762 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 150 || Loss: 0.5395 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 160 || Loss: 0.5334 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 170 || Loss: 0.5411 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 180 || Loss: 0.5621 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 190 || Loss: 0.5373 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 200 || Loss: 0.5574 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 210 || Loss: 0.6334 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 220 || Loss: 0.5342 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 230 || Loss: 0.7688 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 240 || Loss: 0.5928 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 250 || Loss: 0.6262 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 260 || Loss: 0.5376 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 270 || Loss: 0.5994 || 10iter. || 本イテレーションの正解率：1.0\n",
            "Epoch 1/4 | train |  Loss: 0.5803 Acc: 0.9774\n",
            "Epoch 1/4 |  val  |  Loss: 0.6849 Acc: 0.9247\n",
            "イテレーション 10 || Loss: 0.5184 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 20 || Loss: 0.5977 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 30 || Loss: 0.5757 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 40 || Loss: 0.5310 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 50 || Loss: 0.5504 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 60 || Loss: 0.5666 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 70 || Loss: 0.7201 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 80 || Loss: 0.5157 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 90 || Loss: 0.5254 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 100 || Loss: 0.5041 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 110 || Loss: 0.6010 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 120 || Loss: 0.5853 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 130 || Loss: 0.6096 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 140 || Loss: 0.6117 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 150 || Loss: 0.5079 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 160 || Loss: 0.5378 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 170 || Loss: 0.5112 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 180 || Loss: 0.5697 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 190 || Loss: 0.5809 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 200 || Loss: 0.7082 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 210 || Loss: 0.5496 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 220 || Loss: 0.5438 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 230 || Loss: 0.5641 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 240 || Loss: 0.5703 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 250 || Loss: 0.5192 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 260 || Loss: 0.5954 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 270 || Loss: 0.5381 || 10iter. || 本イテレーションの正解率：1.0\n",
            "Epoch 2/4 | train |  Loss: 0.5615 Acc: 0.9851\n",
            "Epoch 2/4 |  val  |  Loss: 0.6962 Acc: 0.9288\n",
            "イテレーション 10 || Loss: 0.5176 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 20 || Loss: 0.6391 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 30 || Loss: 0.5206 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 40 || Loss: 0.5773 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 50 || Loss: 0.5477 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 60 || Loss: 0.5476 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 70 || Loss: 0.5652 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 80 || Loss: 0.5550 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 90 || Loss: 0.5359 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 100 || Loss: 0.5480 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 110 || Loss: 0.5823 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 120 || Loss: 0.5272 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 130 || Loss: 0.5291 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 140 || Loss: 0.5186 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 150 || Loss: 0.5184 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 160 || Loss: 0.5452 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 170 || Loss: 0.5237 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 180 || Loss: 0.5070 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 190 || Loss: 0.7033 || 10iter. || 本イテレーションの正解率：0.875\n",
            "イテレーション 200 || Loss: 0.5758 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 210 || Loss: 0.5070 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 220 || Loss: 0.5462 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 230 || Loss: 0.5105 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 240 || Loss: 0.5657 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 250 || Loss: 0.5066 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 260 || Loss: 0.5282 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 270 || Loss: 0.6043 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "Epoch 3/4 | train |  Loss: 0.5459 Acc: 0.9896\n",
            "Epoch 3/4 |  val  |  Loss: 0.6842 Acc: 0.9315\n",
            "イテレーション 10 || Loss: 0.5123 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 20 || Loss: 0.5130 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 30 || Loss: 0.5129 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 40 || Loss: 0.6029 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 50 || Loss: 0.5320 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 60 || Loss: 0.5206 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 70 || Loss: 0.5393 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 80 || Loss: 0.5139 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 90 || Loss: 0.5153 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 100 || Loss: 0.5880 || 10iter. || 本イテレーションの正解率：0.9375\n",
            "イテレーション 110 || Loss: 0.5258 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 120 || Loss: 0.5345 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 130 || Loss: 0.5202 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 140 || Loss: 0.5373 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 150 || Loss: 0.5131 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 160 || Loss: 0.5167 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 170 || Loss: 0.5488 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 180 || Loss: 0.5045 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 190 || Loss: 0.5229 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 200 || Loss: 0.5485 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 210 || Loss: 0.5069 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 220 || Loss: 0.5440 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 230 || Loss: 0.5058 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 240 || Loss: 0.5049 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 250 || Loss: 0.5236 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 260 || Loss: 0.5303 || 10iter. || 本イテレーションの正解率：1.0\n",
            "イテレーション 270 || Loss: 0.5056 || 10iter. || 本イテレーションの正解率：1.0\n",
            "Epoch 4/4 | train |  Loss: 0.5346 Acc: 0.9923\n",
            "Epoch 4/4 |  val  |  Loss: 0.6767 Acc: 0.9295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8zuZC_0yaOs"
      },
      "source": [
        "## テストデータでの性能を確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMNf7kVdItkl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdxKZzijT5PG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dad5184-8f34-4d92-d253-bb2dc6ff024f"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# テストデータでの正解率を求める\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   # モデルを検証モードに\n",
        "net_trained.to(device)  # GPUが使えるならGPUへ送る\n",
        "\n",
        "# epochの正解数を記録する変数\n",
        "epoch_corrects = 0\n",
        "\n",
        "for batch in tqdm(dl_test):  # testデータのDataLoader\n",
        "    # batchはTextとLableの辞書オブジェクト\n",
        "    # GPUが使えるならGPUにデータを送る\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch.Text[0].to(device)  # 文章\n",
        "    labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "    # 順伝搬（forward）計算\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # BertForLivedoorに入力\n",
        "        outputs = net_trained(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)  # 損失を計算\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        epoch_corrects += torch.sum(preds == labels.data)  # 正解数の合計を更新\n",
        "\n",
        "# 正解率\n",
        "epoch_acc = epoch_corrects.double() / len(dl_test.dataset)\n",
        "\n",
        "print('テストデータ{}個での正解率：{:.4f}'.format(len(dl_test.dataset), epoch_acc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 93/93 [00:55<00:00,  1.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "テストデータ1475個での正解率：0.9356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYvVlrl7y45g"
      },
      "source": [
        "https://yoheikikuta.github.io/bert-japanese/\n",
        "\n",
        "https://github.com/yoheikikuta/bert-japanese\n",
        "\n",
        "の「BERT with SentencePiece for Japanese text.」\n",
        "\n",
        "では、入力テキストにタイトルを含めていますが、今回はタイトルは除いています。\n",
        "\n",
        "同様にタイトルを抜いている、[BERTを用いた日本語文書分類タスクの学習・ハイパーパラメータチューニングの実践例](https://medium.com/karakuri/bert%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E6%97%A5%E6%9C%AC%E8%AA%9E%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%82%BF%E3%82%B9%E3%82%AF%E3%81%AE%E5%AD%A6%E7%BF%92-%E3%83%8F%E3%82%A4%E3%83%91%E3%83%BC%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E5%AE%9F%E8%B7%B5%E4%BE%8B-2fa5e4299b16)でも、正解率が92%ちょっととなっており、ほぼ同じ正解率が得られました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y37pHqN2YD0"
      },
      "source": [
        "以上。"
      ]
    }
  ]
}